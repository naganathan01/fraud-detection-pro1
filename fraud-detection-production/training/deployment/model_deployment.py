# training/deployment/model_deployment.py
import boto3
import joblib
import logging
import requests
import time
from typing import Dict, List
from datetime import datetime
import subprocess
import os

class ModelDeployer:
    """Deploy trained models to different environments"""
    
    def __init__(self):
        self.s3_client = boto3.client('s3')
        self.k8s_namespace = 'fraud-detection'
        self.staging_endpoint = 'http://fraud-api-staging:8000'
        self.production_endpoint = 'http://fraud-api-prod:8000'
        
    def deploy_to_staging(self) -> Dict:
        """Deploy models to staging environment"""
        
        logging.info("üöÄ Starting staging deployment...")
        
        try:
            # Upload models to S3
            model_artifacts = self._upload_models_to_s3()
            
            # Update staging deployment
            deployment_result = self._update_k8s_deployment('staging', model_artifacts)
            
            # Wait for deployment to be ready
            self._wait_for_deployment_ready('staging')
            
            result = {
                'success': True,
                'environment': 'staging',
                'artifacts': model_artifacts,
                'deployed_at': datetime.now().isoformat(),
                'deployment_id': deployment_result.get('deployment_id')
            }
            
            logging.info("‚úÖ Staging deployment completed successfully")
            return result
            
        except Exception as e:
            logging.error(f"‚ùå Staging deployment failed: {e}")
            raise
    
    def deploy_to_production(self, strategy: str = 'blue_green') -> Dict:
        """Deploy models to production environment"""
        
        logging.info(f"üöÄ Starting production deployment with {strategy} strategy...")
        
        try:
            if strategy == 'blue_green':
                result = self._blue_green_deployment()
            elif strategy == 'canary':
                result = self._canary_deployment()
            else:
                raise ValueError(f"Unsupported deployment strategy: {strategy}")
            
            logging.info("‚úÖ Production deployment completed successfully")
            return result
            
        except Exception as e:
            logging.error(f"‚ùå Production deployment failed: {e}")
            raise
    
    def run_smoke_tests(self, environment: str = 'staging') -> Dict:
        """Run smoke tests against deployed models"""
        
        logging.info(f"üß™ Running smoke tests on {environment}...")
        
        endpoint = self.staging_endpoint if environment == 'staging' else self.production_endpoint
        
        test_cases = [
            {
                'name': 'basic_prediction',
                'payload': {
                    'transaction_id': 'TEST_001',
                    'user_id': 'TEST_USER',
                    'amount': 100.0,
                    'location': 'US',
                    'device_type': 'mobile',
                    'is_foreign_transaction': False,
                    'is_high_risk_country': False
                }
            },
            {
                'name': 'high_amount_prediction',
                'payload': {
                    'transaction_id': 'TEST_002',
                    'user_id': 'TEST_USER',
                    'amount': 10000.0,
                    'location': 'CN',
                    'device_type': 'desktop',
                    'is_foreign_transaction': True,
                    'is_high_risk_country': True
                }
            }
        ]
        
        results = {
            'success': True,
            'tests_passed': 0,
            'tests_failed': 0,
            'test_results': [],
            'errors': []
        }
        
        for test_case in test_cases:
            try:
                # Make prediction request
                response = requests.post(
                    f"{endpoint}/api/v1/predict",
                    json=test_case['payload'],
                    headers={'Authorization': 'Bearer test-api-key'},
                    timeout=10
                )
                
                if response.status_code == 200:
                    prediction_result = response.json()
                    
                    # Validate response structure
                    required_fields = ['is_fraud', 'fraud_probability', 'risk_score']
                    if all(field in prediction_result for field in required_fields):
                        results['tests_passed'] += 1
                        results['test_results'].append({
                            'test': test_case['name'],
                            'status': 'passed',
                            'response_time_ms': response.elapsed.total_seconds() * 1000,
                            'prediction': prediction_result
                        })
                    else:
                        raise ValueError(f"Missing required fields in response: {required_fields}")
                else:
                    raise ValueError(f"HTTP {response.status_code}: {response.text}")
                    
            except Exception as e:
                results['success'] = False
                results['tests_failed'] += 1
                results['errors'].append({
                    'test': test_case['name'],
                    'error': str(e)
                })
        
        logging.info(f"‚úÖ Smoke tests completed: {results['tests_passed']} passed, {results['tests_failed']} failed")
        return results
    
    def _upload_models_to_s3(self) -> Dict:
        """Upload model artifacts to S3"""
        
        model_files = {
            'xgboost': '/tmp/xgboost_model.pkl',
            'lightgbm': '/tmp/lightgbm_model.pkl',
            'random_forest': '/tmp/random_forest_model.pkl',
            'ensemble': '/tmp/ensemble_model.pkl'
        }
        
        bucket = 'fraud-detection-models'
        version = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        uploaded_artifacts = {}
        
        for model_name, local_path in model_files.items():
            if os.path.exists(local_path):
                s3_key = f"models/{version}/{model_name}_model.pkl"
                
                try:
                    self.s3_client.upload_file(local_path, bucket, s3_key)
                    uploaded_artifacts[model_name] = f"s3://{bucket}/{s3_key}"
                    logging.info(f"‚úÖ Uploaded {model_name} to S3")
                except Exception as e:
                    logging.error(f"‚ùå Failed to upload {model_name}: {e}")
        
        return uploaded_artifacts
    
    def _update_k8s_deployment(self, environment: str, artifacts: Dict) -> Dict:
        """Update Kubernetes deployment with new model version"""
        
        # In a real implementation, this would update the K8s deployment
        # with new environment variables pointing to the new model artifacts
        
        deployment_config = {
            'MODEL_VERSION': datetime.now().strftime('%Y%m%d_%H%M%S'),
            'MODEL_ARTIFACTS': artifacts,
            'UPDATED_AT': datetime.now().isoformat()
        }
        
        # Simulate kubectl apply
        logging.info(f"üîÑ Updating {environment} deployment with config: {deployment_config}")
        
        return {
            'deployment_id': f"fraud-detection-{environment}-{deployment_config['MODEL_VERSION']}",
            'config': deployment_config
        }
    
    def _wait_for_deployment_ready(self, environment: str, timeout: int = 300):
        """Wait for deployment to be ready"""
        
        logging.info(f"‚è≥ Waiting for {environment} deployment to be ready...")
        
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            try:
                # Check health endpoint
                endpoint = self.staging_endpoint if environment == 'staging' else self.production_endpoint
                response = requests.get(f"{endpoint}/health/ready", timeout=5)
                
                if response.status_code == 200:
                    logging.info(f"‚úÖ {environment} deployment is ready")
                    return True
                    
            except requests.exceptions.RequestException:
                pass
            
            time.sleep(10)
        
        raise TimeoutError(f"Deployment {environment} not ready after {timeout} seconds")
    
    def _blue_green_deployment(self) -> Dict:
        """Implement blue-green deployment strategy"""
        
        logging.info("üîÑ Executing blue-green deployment...")
        
        # Step 1: Deploy to green environment
        green_deployment = self._update_k8s_deployment('green', {})
        self._wait_for_deployment_ready('green')
        
        # Step 2: Run smoke tests on green
        smoke_tests = self.run_smoke_tests('green')
        if not smoke_tests['success']:
            raise ValueError(f"Smoke tests failed on green environment: {smoke_tests['errors']}")
        
        # Step 3: Switch traffic to green
        self._switch_traffic('green')
        
        # Step 4: Monitor for 5 minutes
        time.sleep(300)
        
        # Step 5: Decommission blue
        self._decommission_environment('blue')
        
        return {
            'strategy': 'blue_green',
            'success': True,
            'green_deployment': green_deployment,
            'smoke_tests': smoke_tests,
            'deployed_at': datetime.now().isoformat()
        }
    
    def _canary_deployment(self) -> Dict:
        """Implement canary deployment strategy"""
        
        logging.info("üîÑ Executing canary deployment...")
        
        # Step 1: Deploy canary with 5% traffic
        canary_deployment = self._update_k8s_deployment('canary', {})
        self._wait_for_deployment_ready('canary')
        self._set_traffic_split({'production': 95, 'canary': 5})
        
        # Step 2: Monitor for 10 minutes
        time.sleep(600)
        canary_metrics = self._get_canary_metrics()
        
        # Step 3: Validate canary performance
        if not self._validate_canary_performance(canary_metrics):
            self._rollback_canary()
            raise ValueError("Canary performance validation failed")
        
        # Step 4: Increase to 25% traffic
        self._set_traffic_split({'production': 75, 'canary': 25})
        time.sleep(600)
        
        # Step 5: Full rollout
        self._set_traffic_split({'canary': 100})
        self._promote_canary_to_production()
        
        return {
            'strategy': 'canary',
            'success': True,
            'canary_deployment': canary_deployment,
            'metrics': canary_metrics,
            'deployed_at': datetime.now().isoformat()
        }
    
    def _switch_traffic(self, target_environment: str):
        """Switch traffic to target environment"""
        logging.info(f"üîÑ Switching traffic to {target_environment}")
        # Implementation depends on load balancer/ingress controller
        
    def _set_traffic_split(self, split: Dict[str, int]):
        """Set traffic split percentages"""
        logging.info(f"üîÑ Setting traffic split: {split}")
        # Implementation depends on service mesh/ingress controller
        
    def _get_canary_metrics(self) -> Dict:
        """Get canary deployment metrics"""
        # In production, collect real metrics from monitoring system
        return {
            'error_rate': 0.001,
            'avg_latency_ms': 45,
            'throughput_rps': 150,
            'cpu_usage': 0.35,
            'memory_usage': 0.62
        }
    
    def _validate_canary_performance(self, metrics: Dict) -> bool:
        """Validate canary performance against thresholds"""
        thresholds = {
            'error_rate': 0.01,
            'avg_latency_ms': 100,
            'cpu_usage': 0.8,
            'memory_usage': 0.8
        }
        
        for metric, value in metrics.items():
            if metric in thresholds and value > thresholds[metric]:
                logging.warning(f"‚ùå Canary metric {metric} ({value}) exceeds threshold ({thresholds[metric]})")
                return False
        
        return True
    
    def _rollback_canary(self):
        """Rollback canary deployment"""
        logging.info("üîÑ Rolling back canary deployment")
        self._set_traffic_split({'production': 100})
        
    def _promote_canary_to_production(self):
        """Promote canary to production"""
        logging.info("üîÑ Promoting canary to production")
        # Update production deployment to canary version
        
    def _decommission_environment(self, environment: str):
        """Decommission old environment"""
        logging.info(f"üóëÔ∏è Decommissioning {environment} environment")
        # Clean up old deployment